---
title: "COMPSCIX 415.2 Homework 5/Midterm"
author: "ben kimel green"
date: "2/27/2019"
output: 
  html_document: 
    theme: yeti
    toc: yes
    toc_depth: 2
---
# Midterms
### [my github link](https://github.com/benkimel/learnR)
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```
## The tidyverse packages

#### 1. Can you name which package is associated with each task below?
  + Plotting - ggplot2
  + Data munging/wrangling - dplyr
  + Reshaping (speading and gathering) data - tidyr
  + Importing/exporting data - readr
  
#### 2. Now can you name two functions that you’ve used from each package that you listed above for these tasks?

  + ggplot2 - ggplot, geom_point
  + dplyr - filter, summarise
  + tidyr - spread, separate
  + readr - read_csv, write_delim

##R Basics 

#### 1. Fix this code with the fewest number of changes possible so it works:

```{r}
My_data.name___is.too00ooLong <- c( 1 , 2   , 3 )
```

#### 2. Fix this code so it works:

```{r}
my_string <- c('has', 'an', 'error', 'in', 'it')
```

#### 3. Look at the code below and comment on what happened to the values in the vector.
The vector changed all the values to be of type char

```{r}
my_vector <- c(1, 2, '3', '4', 5)
my_vector
```

## Data import/export

#### 1. Download the rail_trail.txt file from Canvas (in the Midterm Exam section) and successfully import it into R. Prove that it was imported successfully by including your import code and taking a glimpse of the result.
```{r}
file_path <- '~/Desktop/rail_trail.txt'
trails <- read_delim(file = file_path,delim = "|")
glimpse(trails)
```

#### 2. Export the file into a comma-separated file and name it “rail_trail.csv”. Make sure you define the path correctly so that you know where it gets saved. Then reload the file. Include your export and import code and take another glimpse.
```{r}
file_path_write <- '~/Desktop/rail_trail.csv'
write_csv(trails,file_path_write)
trails_csv <- read_csv(file = file_path_write)
glimpse(trails_csv)
```
##Visualization

#### 1.Critique this graphic: give only three examples of what is wrong with this graphic. Be concise.

1. Combining age related description together with gender. I would use 2 diffrent graphics.
2. Using a sized circle to show propetion from is confusing. Bar chart or even pie chart would have been nicer. 
3. The numbers don't add up to 100% and the 10%-5%  missing are not explained

#### 2. Reproduce this graphic using the `diamonds` data set.
```{r}
data(diamonds)
ggplot(data = diamonds) +
  geom_boxplot(mapping = aes(x = cut, y = carat, fill = color),position = "identity")+
  scale_fill_brewer(palette="Set2")+
  labs(x = "CUT OF DIAMONDS", y = "CARAT OF DIAMOND")+
  coord_flip()
```

##Data munging and wrangling

#### 1. Is this data “tidy”? If yes, leave it alone and go to the next problem. If no, make it tidy. 
The data in `table2` is not "tidy" as it has cases of TB and country population as diffrent enteries.<br/>
It is better to have a row for each country for each year as in modifyed data below.
```{r}
data(table2)
fixed_table2 <- table2%>% spread(key = type,value = count)
head(fixed_table2)
```


#### 2. Create a new column in the diamonds data set called price_per_carat that shows the price of each diamond per carat (hint: divide). Only show me the code, not the output.
```{r}
data(diamonds)
new_diamonds = diamonds%>%mutate("price_per_carat" = price/carat)
```

#### 3. For each cut of diamond in the diamonds data set, how many diamonds, and what proportion, have a price > 10000 and a carat < 1.5? There are several ways to get to an answer, but your solution must use the data wrangling verbs from the tidyverse in order to get credit.
+ Do the results make sense? Why?
As much as I understand they make sense more or less. But I dn't know if 1000$ (or more) for diamonds under 1.5 carat is reasonable. by the proportion calculation it seems most of the data set is that way.
+ Do we need to be wary of any of these numbers? Why?
It seems the proportion of high price and under then 1.5 carat is bigger in the `fair` cut and drops a little bit the better the cut is. This is the opessite of what 
I would expect. This maybe due to the fact that the amount of diamonds in the data set is bigger for better cuts a fact that can increase variation. 
```{r}
diamonds%>%group_by(cut) %>%summarise("high_price_small_carat_num"=sum(carat<1.5&price>1000),"proportion" = sum(carat<1.5&price>1000)/n(), "N" = n())
```

##EDA

#### Take a look at the txhousing data set that is included with the ggplot2 package and answer these questions:
```{r}
data(txhousing)
```

* During what time period is this data from?<br/>
A: 2000-2015
```{r}
max(txhousing$year)
min(txhousing$year)
```

* How many cities are represented?<br/>
A: 46
```{r}
txhousing%>%count(city)%>%summarise(n=n())
```

* Which city, month and year had the highest number of sales?<br/>
A: Houston had max total sales. June was the month with nost sales. 2006 was the year with most sales.
```{r}
txhousing%>%count(city,wt = sales)%>%arrange(desc(n))
txhousing%>%count(month,wt = sales)%>%arrange(desc(n))
txhousing%>%count(year,wt = sales)%>%arrange(desc(n))
```

* What kind of relationship do you think exists between the number of listings and the number of sales? Check your assumption and show your work.<br/>
A:My guess is the more listing there are there will be more sales. Maybe up to a point where there some extreme case where the qmount of listing is stable but sales drop (no one is buying and listings stay up).
After ploting the relations between the values it seems there is a general tendency to have more sales when there are more listings. this dosn't say much since it is more then likely a result of city size. This data does not contain city size or population so I won't try to factor that in.
```{r}
ggplot(txhousing,aes(x= listings, y = sales))+geom_point()
```

* What proportion of sales is missing for each city?
```{r}
txhousing%>%count(city,wt = is.na(sales)/n())%>%arrange(desc(n))

```

* Looking at only the cities and months with greater than 500 sales:
    - Are the distributions of the median sales price (column name median), when grouped by city,           different? The same? Show your work.<br/>
      A: not sure about the meaning of this.... I will skip :(
    - Any cities that stand out that you’d want to investigate further?<br/>
      A: I think it could be intresting to look at low inventory time cities to understand why sales are so fast in them.
    - Why might we want to filter out all cities and months with sales less than 500?<br/>
      A: 500 is a large enough number to figure statistical trends. With lower numbers we may get more influance of extreme cases.
    
```{r}
big_sales<-txhousing%>%filter(sales>500)
big_sales%>%arrange(inventory)
```
  
  